{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Before usage of this API, \n",
    "please ensure the following packages are installed. \n",
    "\n",
    "Tensorflow: 1.11.0\n",
    "Keras: 2.2.4\n",
    "NumPy: 1.15.1\n",
    "\n",
    "Note that you can directly install these packages in ipython notebook\n",
    "through commands like \"!pip install tensorflow==1.11\"\n",
    "'''\n",
    "\n",
    "# Let's start our demestration\n",
    "# For this grid, we import some packages and utils.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras \n",
    "\n",
    "import random, math\n",
    "\n",
    "# You can use the API without creating an utils instance, \n",
    "# We create an utils instance here for printing some information \n",
    "# to illustrate that our operators function correctly \n",
    "import utils\n",
    "utils = utils.GeneralUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_datas shape: (5000, 784)\n",
      "train_labels shape: (5000,)\n",
      "test_datas shape: (1000, 784)\n",
      "test_labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training dataset and untrained model for source-level mutation \n",
    "# Users can their our own dataset and model\n",
    "import network \n",
    "network = network.SimplyNetwork()\n",
    "\n",
    "# model is a simple FC(fully-connected) neural network\n",
    "# dataset is a subset from MNIST dataset with 5000 training data and 1000 testing data\n",
    "model = network.create_debug_model()\n",
    "(train_datas, train_labels), (test_datas, test_labels) = network.load_data()\n",
    "\n",
    "print('train_datas shape:', train_datas.shape)\n",
    "print('train_labels shape:', train_labels.shape)\n",
    "print('test_datas shape:', test_datas.shape)\n",
    "print('test_labels shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of source-level mutation operators API\n",
    "import source_mut_operators\n",
    "source_mut_opts = source_mut_operators.SourceMutationOperators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DR, where the mutation ratio is 0.01\n",
      "Train data shape: (5050, 784)\n",
      "Train labels shape: (5050,)\n",
      "\n",
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DR, where the mutation ratio is 0.1\n",
      "Train data shape: (5500, 784)\n",
      "Train labels shape: (5500,)\n",
      "\n",
      "Before DR\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DR, where the mutation ratio is 0.5\n",
      "Train data shape: (7500, 784)\n",
      "Train labels shape: (7500,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DR (Data Repetition), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (DR_train_datas, DR_train_labels), DR_model = source_mut_opts.DR_mut((train_datas, train_labels), model, mutation_ratio)\n",
    "    \n",
    "    utils.print_messages_SMO('DR', train_datas=train_datas, train_labels=train_labels, mutated_datas=DR_train_datas, mutated_labels=DR_train_labels, mutation_ratio=mutation_ratio)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation ratio: 0.01\n",
      "Number of mislabeled labels: 50\n",
      "\n",
      "Mutation ratio: 0.1\n",
      "Number of mislabeled labels: 500\n",
      "\n",
      "Mutation ratio: 0.5\n",
      "Number of mislabeled labels: 2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LE (Label Error), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (LE_train_datas, LE_train_labels), LE_model = source_mut_opts.LE_mut((train_datas, train_labels), model, 0, 9, mutation_ratio)\n",
    "    \n",
    "    mask_equal = LE_train_labels == train_labels\n",
    "    count_diff = len(train_labels) - np.sum(mask_equal)\n",
    "    print('Mutation ratio:', mutation_ratio)\n",
    "    print('Number of mislabeled labels:', count_diff)\n",
    "    print('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DM, where the mutation ratio is 0.01\n",
      "Train data shape: (4950, 784)\n",
      "Train labels shape: (4950,)\n",
      "\n",
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DM, where the mutation ratio is 0.1\n",
      "Train data shape: (4500, 784)\n",
      "Train labels shape: (4500,)\n",
      "\n",
      "Before DM\n",
      "Train data shape: (5000, 784)\n",
      "Train labels shape: (5000,)\n",
      "\n",
      "After DM, where the mutation ratio is 0.5\n",
      "Train data shape: (2500, 784)\n",
      "Train labels shape: (2500,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DM (Data Missing), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratios = [0.01, 0.1, 0.5]\n",
    "for mutation_ratio in mutation_ratios:\n",
    "    \n",
    "    (DM_train_datas, DM_train_labels), DM_model = source_mut_opts.DM_mut((train_datas, train_labels), model, mutation_ratio)\n",
    "    \n",
    "    utils.print_messages_SMO('DM', train_datas=train_datas, train_labels=train_labels, mutated_datas=DM_train_datas, mutated_labels=DM_train_labels, mutation_ratio=mutation_ratio)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For DF, it's a little difficult to explicitly demonstrate\n",
    "a large amount of data samples be shuffled. \n",
    "Here, we simply illustrate how to use DF mutation operator.\n",
    "'''\n",
    "# DF (Data Shuffle), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratio = 0.01\n",
    "(DF_train_datas, DF_train_labels), DF_model = source_mut_opts.DF_mut((train_datas, train_labels), model, mutation_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Mutated data after NP mutation [-1.17969065e+00  2.07089693e-01  9.31958009e-03  1.20714499e+00\n",
      " -1.06472870e+00 -3.29954350e+00  5.06890818e-01 -1.53743969e+00\n",
      "  2.00717407e+00  7.14482063e-01 -5.24282696e-01  2.02805996e+00\n",
      " -1.10150550e+00  2.94408215e-01 -1.70610793e+00  5.49386707e-01\n",
      " -3.22735869e-01 -7.70291454e-01  3.77022898e-04 -2.44645435e+00\n",
      "  1.31989182e-01  1.18271081e-01 -1.01693366e+00 -1.22789104e+00\n",
      "  1.22397416e-01  1.57774489e-01 -8.25204126e-01 -4.90701458e-01\n",
      "  2.38225823e-03 -2.65523207e+00 -5.72178315e-01 -2.91368163e-01\n",
      " -2.69217292e-01  1.28740697e-01  3.80497450e-01 -1.06056752e+00\n",
      " -8.40217292e-02 -4.87133174e-02 -3.27108489e-01  2.75063340e-01\n",
      " -2.42910609e-02  5.84241280e-01 -9.45588795e-01 -4.31159651e-01\n",
      " -6.58316103e-01  1.00704314e+00 -8.78532142e-01  2.20554779e-01\n",
      "  4.65267370e-01 -3.58509082e-01 -4.43537981e-01 -2.01606197e+00\n",
      " -8.91280056e-02 -5.05758675e-01 -5.53775234e-02 -1.87954433e+00\n",
      " -1.45895043e+00  1.04177995e+00  5.48170559e-01 -1.28425005e+00\n",
      " -5.37295094e-01  5.14249114e-01 -4.91644416e-01 -9.14959856e-01\n",
      "  1.62871494e+00  3.79940026e-01  4.39730340e-01 -6.19885682e-01\n",
      " -4.64819156e-01 -3.69400060e-01 -2.08706548e-01 -3.77936003e-01\n",
      "  9.98780815e-01  8.12631214e-01 -4.10345905e-01  7.38441628e-01\n",
      "  2.08148820e-01 -5.13363550e-01  1.22645212e+00  1.82699027e-01\n",
      " -6.33788528e-01 -4.52745778e-01 -1.75580270e+00 -2.97813538e-01\n",
      "  9.95576157e-01 -1.19503237e+00 -1.20887740e+00  8.93365847e-01\n",
      "  2.75508176e-01 -1.24707418e-01 -6.82769305e-01 -1.29528119e+00\n",
      "  5.39570782e-01 -3.97967776e-01 -8.59447294e-02  1.92694925e-01\n",
      "  2.17614408e+00  2.72020166e-01 -5.39606834e-01 -4.56334338e-01\n",
      " -9.97705449e-02  5.79712181e-01 -3.99997644e-01  1.06192606e+00\n",
      "  1.17558788e+00 -9.40997018e-01  8.93926275e-01  1.17370683e+00\n",
      "  9.61719148e-01  1.38096998e+00 -5.44987859e-01  1.15485878e+00\n",
      " -1.09816085e+00 -8.14650225e-01 -4.08781292e-01 -9.37934901e-01\n",
      "  6.55380894e-01  2.26802167e+00  8.41051390e-01 -1.08636730e-01\n",
      " -2.28987775e+00 -5.25403982e-01  1.25996566e+00 -1.01079979e+00\n",
      "  3.33596916e-02 -1.95229503e+00  1.44758144e+00 -2.73573079e-01\n",
      "  2.09592925e+00 -4.38265492e-01  1.54694714e-01 -1.47393387e+00\n",
      " -2.09530731e+00  1.01827434e+00  9.87228303e-01 -1.61573043e-01\n",
      "  1.38842045e+00 -1.19626068e-01  5.16544864e-01 -5.28688992e-01\n",
      " -1.41491813e+00 -3.41359918e-01 -5.07853590e-02  1.65078728e+00\n",
      " -1.89349593e-02 -1.15861022e+00  1.12159527e+00  1.87383446e-01\n",
      " -4.20746239e-01  3.62794445e-01  2.83463055e-02  3.39945200e-01\n",
      "  7.17141227e-01  1.58010620e+00 -1.16488797e+00 -2.21166183e+00\n",
      "  1.80884509e-02  4.82861779e-01  1.11296388e+00  8.09066330e-01\n",
      "  2.16320873e+00  2.70213995e+00  2.08063222e+00 -2.35456578e-01\n",
      " -8.15360998e-01 -1.08612955e-01 -5.00976685e-01 -1.16830588e+00\n",
      " -4.56401565e-01  4.32768208e-01  6.74903095e-01 -5.56270749e-01\n",
      "  1.12836767e+00  1.29838764e+00  2.43337512e-01 -3.55220450e-01\n",
      "  5.03625385e-01 -1.17585758e+00  6.86455033e-01  7.06307902e-01\n",
      "  1.22507182e+00  3.89538633e-01  1.86545401e+00  1.55457943e+00\n",
      " -2.57984261e-01  1.20298374e+00  1.37749528e+00  3.03429979e-01\n",
      "  8.44027140e-01  1.94951448e+00 -6.07166325e-01 -2.84438375e-01\n",
      "  2.03022498e+00 -1.02540440e+00  3.08755697e-01  2.53823465e+00\n",
      "  2.49828201e-01 -1.41006881e+00 -5.88712640e-01 -1.14725206e+00\n",
      " -2.98457472e-01  7.08380426e-02  5.68272109e-01  2.21478370e-02\n",
      "  3.65929218e-01 -4.21576990e-03  1.86880174e+00  1.81898675e-01\n",
      "  3.45256954e+00 -3.21716206e-01  3.44494360e-01  1.09175607e+00\n",
      "  1.50647607e+00  1.02422775e+00  8.78128553e-03 -5.75487875e-01\n",
      "  3.70852204e-01  3.73553341e-01  1.80338632e+00  5.41655345e-01\n",
      "  3.74404708e-01  6.91297630e-01  2.04001065e+00 -4.15744236e-02\n",
      " -8.42914219e-01 -6.40299558e-02  8.07568564e-02  1.13431328e+00\n",
      " -1.34363287e+00 -1.00431652e+00  5.87148910e-01  2.34859281e+00\n",
      " -6.58629584e-01 -2.11095128e-02  5.73245885e-01 -1.04172783e-01\n",
      " -4.44904104e-01  4.39513876e-01  2.17183179e+00  1.72844511e+00\n",
      "  1.33895390e+00  5.00695777e-01  4.03593482e-01 -4.26745767e-01\n",
      " -1.02345489e+00  8.43057739e-01  5.35740999e-01  6.51306242e-01\n",
      "  1.36802818e+00  2.71630863e-01 -1.72787084e+00  1.07881757e+00\n",
      "  7.41559444e-02  9.46471477e-01 -1.90107736e+00 -4.97531447e-01\n",
      " -1.09033336e+00 -6.26932850e-01 -6.46367260e-02  4.46104194e-01\n",
      " -1.26665869e+00 -4.03418597e-01  7.04932986e-01  2.25938854e-01\n",
      "  5.10285756e-01  4.41014360e-01  1.56618386e+00  1.29741836e+00\n",
      "  6.93438990e-01  2.19626679e+00  4.48086933e-02 -1.92999636e+00\n",
      " -5.51894193e-01  3.92239858e-01  1.01757808e+00 -2.93582319e-02\n",
      " -2.68558413e-01 -8.02970192e-01  5.23040420e-03 -1.45937786e+00\n",
      "  5.42437620e-01  4.50966172e-01  7.75297412e-01 -2.51630353e+00\n",
      "  7.65502082e-01  3.25897547e-01  7.90367806e-01 -1.05156475e+00\n",
      " -9.66423241e-01  3.38279185e-03 -8.62564251e-01 -3.51225844e-02\n",
      "  6.49995888e-01  1.70522265e+00  1.81099933e-01 -6.13429073e-01\n",
      " -1.06070000e+00 -8.80588994e-02  1.44934053e+00 -2.40365572e-01\n",
      "  9.90069481e-01  1.17313342e-01 -6.32294290e-01 -1.63407769e+00\n",
      "  1.55847756e+00  5.31030072e-01  1.91288833e+00 -1.40096926e+00\n",
      "  1.43448613e+00  7.47351875e-01 -6.62128482e-02  1.53029566e+00\n",
      " -1.07699613e+00 -7.48180849e-01  2.06305606e-01  1.02349865e+00\n",
      "  1.89437140e+00 -9.49692002e-01 -9.81948508e-01 -8.92693960e-02\n",
      "  7.21633161e-01  1.48086716e+00 -1.63226534e-01 -3.71134578e-01\n",
      " -1.29396811e+00  2.25313043e-01  2.64233788e-01 -1.86901273e+00\n",
      "  1.53698349e+00 -2.26667948e-01  3.79064245e-02  2.39252655e-01\n",
      "  4.36843201e-01  6.63317655e-01 -7.74387264e-01  7.25697969e-01\n",
      " -1.23223687e+00  5.78952422e-01 -1.88862368e-01  3.49936601e-01\n",
      "  2.74904352e-01 -1.23244318e+00  8.57867865e-01  8.48686048e-01\n",
      "  3.67735065e-01  3.14269257e-01 -9.99869777e-02 -1.07847996e+00\n",
      "  5.88847816e-01  1.17619377e+00  1.55580892e+00  7.39804626e-02\n",
      " -3.58946974e-02 -1.32971881e+00  1.28483021e+00 -4.54449143e-01\n",
      " -6.11219588e-01  3.32750418e-02 -5.42974945e-01 -3.42719497e-01\n",
      "  1.94099889e+00 -1.32601489e-01 -1.11102584e+00  1.23777773e+00\n",
      " -1.41348416e+00  9.99737168e-01 -5.32711276e-01  2.36724911e+00\n",
      " -1.56834219e+00 -4.83541358e-01 -7.31964507e-01 -8.27981654e-01\n",
      " -1.17609264e-01  8.28347852e-01  6.11086257e-01  1.23406179e+00\n",
      "  8.43533367e-01  5.92396042e-01  3.90787383e-01  6.07004174e-01\n",
      "  1.64390463e+00  9.45988176e-01  6.54722387e-03 -7.41910797e-01\n",
      " -1.96830125e-02 -1.36710649e-01 -5.23649983e-01 -3.26392534e-01\n",
      "  1.76847194e+00 -7.54729806e-01 -1.44078309e+00  8.76310569e-01\n",
      "  6.05201912e-01 -2.11840298e-01 -6.66212233e-01  1.87341795e+00\n",
      " -9.80480779e-01  2.99257778e-02  6.54353963e-01 -2.48436504e-01\n",
      "  1.77081279e+00 -1.45786967e+00 -1.84687323e-01  1.00001072e+00\n",
      " -1.27995380e+00  1.11784898e+00  1.85801394e+00 -9.04805105e-01\n",
      "  1.42729913e+00  6.59017763e-01 -5.80137763e-01  1.49601369e-01\n",
      " -1.96769370e+00 -2.30324136e-01  1.41684577e-01  8.76399268e-01\n",
      " -1.71316387e-01  5.61335663e-01 -3.20505073e-01  2.17469510e-01\n",
      "  9.09610099e-01 -6.20734519e-02  1.95648363e-01 -1.15853622e+00\n",
      " -2.55510000e-01  2.86573779e-01  3.72740695e-01  9.11892692e-02\n",
      "  7.33816339e-02 -3.90530934e-01  1.22867902e+00  2.13290913e-01\n",
      " -1.73385123e+00  2.30451419e+00 -7.30811376e-01  3.02552009e-01\n",
      "  1.49409008e-01  2.36125559e+00  1.59382858e+00 -4.12782595e-02\n",
      "  1.42861817e+00  1.29017203e+00 -5.29671717e-01 -8.91976945e-01\n",
      " -1.91391088e+00  9.36108374e-02  1.22588472e-01 -2.56229633e+00\n",
      "  6.98530805e-01  5.76307900e-01 -3.75331167e-01 -3.95639970e-01\n",
      "  7.24954787e-01  2.28329154e-01  2.90638792e-01  1.04421210e+00\n",
      "  1.27518414e-01 -4.90853272e-01  6.42768109e-01  8.06633648e-02\n",
      " -1.13095694e+00  1.57477623e+00 -1.26606941e+00 -8.87767483e-01\n",
      "  1.40183679e+00  6.00377002e-01  4.72388324e-01  4.22826038e-01\n",
      "  9.26319174e-01 -3.33997918e-01  1.67670273e-01  1.60294913e+00\n",
      "  1.19585438e+00 -1.04701680e+00  1.19634270e+00  1.07617863e+00\n",
      " -3.68521606e-01  1.12650519e+00 -2.20270533e+00  5.94774135e-01\n",
      " -3.31863035e-01  6.78939100e-01 -3.63092439e-01 -6.99229386e-01\n",
      "  1.46720051e+00  1.56114725e-01 -6.11684754e-01 -6.12500666e-01\n",
      " -6.23875053e-02 -5.30627812e-02 -4.06391041e-02 -9.10219635e-01\n",
      "  5.61973053e-01 -5.39382162e-01  1.62537764e+00  5.84256435e-01\n",
      "  1.64179662e+00  7.95884707e-01 -6.84814501e-01 -2.20219676e-01\n",
      " -1.33920086e+00  4.38050732e-01  1.17014572e+00  2.82113592e-01\n",
      " -7.64936275e-02 -7.21093200e-01 -5.03181625e-01 -1.86176944e+00\n",
      " -2.04137723e+00 -1.35657107e-01  3.30337165e-01  1.09282543e+00\n",
      " -1.11821849e+00  1.30111618e+00 -2.65796472e-01  6.96104208e-01\n",
      "  1.27792259e+00 -1.23035149e+00 -2.48439304e-01  1.08424825e-02\n",
      " -3.56932758e-03  1.29570449e+00  1.38869884e+00  5.29618987e-01\n",
      "  1.14465982e+00 -2.73076388e-01  4.54224932e-01 -4.00904437e-01\n",
      "  7.79415727e-01 -1.93334059e+00  3.09077508e-01 -1.65164706e+00\n",
      "  1.14893828e+00 -1.57509678e+00 -3.53714474e-01 -4.20739160e-01\n",
      "  9.45715469e-01 -1.15777579e+00 -7.03492759e-01 -2.15623985e-01\n",
      " -1.11297063e-02  9.32739732e-02  4.40937936e-01  1.34444731e+00\n",
      " -3.85339100e-01  4.50594189e-02  3.39480801e-02  8.88785582e-01\n",
      "  1.37007568e+00  1.84276014e+00  5.94754638e-01  1.26483302e+00\n",
      " -7.43866376e-01 -8.74635338e-01  1.35891498e-01 -4.43042461e-01\n",
      " -2.44062054e-01 -8.51877898e-01  2.12799585e-01 -4.82354503e-01\n",
      "  8.28255819e-01  5.28087951e-01 -5.92339137e-01  8.69425395e-01\n",
      " -5.61466513e-01 -1.80497051e-01  6.49969505e-01 -1.30215954e+00\n",
      "  8.54961477e-01 -1.45510667e-01  5.54511149e-01  5.19145664e-01\n",
      "  8.42555954e-01  2.42543501e-01  1.47438717e+00  1.18997818e+00\n",
      "  2.07584248e+00  2.19751635e+00 -2.15963521e-01  2.26385531e-01\n",
      "  9.89963104e-01  5.45081245e-01 -1.51018803e+00  8.33518335e-02\n",
      "  3.68213299e-01 -1.53737652e+00  1.04961642e+00 -9.84306337e-01\n",
      "  2.44337857e-01  5.32288106e-01  2.10701365e-01 -1.13405282e+00\n",
      " -4.74377953e-02  1.40206498e+00 -1.09611503e+00 -5.38837000e-03\n",
      " -8.64481853e-01  1.22478331e-01  1.79107911e+00 -7.00010779e-02\n",
      " -2.96842418e-01  8.81072091e-02  1.42951373e+00  1.48114813e+00\n",
      "  1.05913515e+00  1.97847976e-01  1.05591097e-01 -7.23777767e-01\n",
      "  3.47476627e-01 -1.06678183e+00  1.37940483e-01  8.39841711e-01\n",
      "  1.15649749e+00 -1.24649222e+00  6.45684639e-01 -3.73860693e-01\n",
      " -7.85009798e-01  7.29612994e-01 -1.28563395e-01  4.55724566e-01\n",
      "  1.18717886e+00  8.71791964e-01 -1.57080589e-01  4.64160986e-01\n",
      " -7.66241076e-01  1.06135663e+00  2.81960960e-01  6.28925422e-01\n",
      " -8.13738194e-01  2.19240581e+00  1.67535287e+00  7.78068558e-02\n",
      "  3.34367710e-02 -5.06769088e-01 -1.31947899e+00  4.36570634e-01\n",
      " -9.70633353e-01 -7.56410815e-01 -1.81637178e+00 -1.25167699e+00\n",
      "  1.03501929e+00  1.59430784e+00 -9.17907613e-01 -7.90441603e-01\n",
      " -1.27728735e+00 -1.65576085e+00  1.42983606e+00 -1.55718542e+00\n",
      "  1.67026104e+00  6.99869950e-01  6.99111103e-01  1.58125989e+00\n",
      " -1.79996199e-01 -1.44249994e-01  8.75703129e-01  7.37271806e-01\n",
      "  5.70456871e-01 -5.21667530e-01 -5.37026856e-01  1.67611579e+00\n",
      "  1.90990373e-01  7.84065560e-01 -8.11339054e-01  2.51259266e+00\n",
      " -1.34994944e+00  4.46435899e-02 -1.22793356e+00 -1.43579398e-01\n",
      " -1.68749860e+00  3.19159325e-01 -2.69817347e-01 -6.79232610e-01\n",
      "  3.61674948e-01 -1.49966557e+00 -1.52754998e+00 -9.40081783e-01\n",
      "  2.92115587e+00  1.22331197e+00 -1.62928276e+00  2.02459379e+00\n",
      "  2.49570416e+00  8.18196990e-02  2.54733597e-01  3.36973846e-01\n",
      "  1.73684319e+00 -9.83467561e-02  9.53270968e-01 -1.37982478e-01\n",
      " -2.46859414e-01  4.45293416e-01 -1.44389511e+00 -2.39509799e-01\n",
      "  7.03333162e-02  3.22325650e-01  1.23493157e+00 -2.04585002e+00\n",
      " -1.83518431e-01  1.00787418e+00  8.89975073e-01  6.78422735e-01\n",
      " -4.77894112e-01  2.07470673e+00 -3.43528784e-01  8.09327462e-01\n",
      "  4.24312501e-01 -5.92424108e-02  2.00537914e+00  4.41064513e-01\n",
      " -8.84257132e-02  9.16662522e-02 -1.64849504e+00  6.10537134e-01\n",
      "  2.47345396e-01 -2.51538242e-01 -4.45602348e-01 -4.76089859e-01\n",
      "  1.30379623e+00 -4.31709929e-01  2.04307073e-01 -2.54090645e+00\n",
      " -3.28719266e-01  9.51815411e-01  1.23976094e+00 -2.50788405e-01\n",
      "  1.16918489e+00 -1.13755891e-01 -6.28277479e-01 -8.08588974e-02\n",
      " -1.08080312e+00  7.80965589e-01  5.42788186e-01 -1.54567708e+00\n",
      " -3.25534360e-01 -1.33315175e-01  2.88584446e-02 -1.51240453e+00\n",
      " -8.66965285e-01 -4.45924795e-01  5.61367843e-01  6.29652503e-02\n",
      "  6.27586229e-01  1.94726748e+00 -6.65038206e-02  1.14788409e+00\n",
      "  2.02305370e-02  1.37365497e-01 -1.39361697e+00  6.00427604e-01\n",
      " -4.64875558e-01 -3.46153820e-01 -6.06945331e-01  4.98596470e-01\n",
      " -1.61547425e+00  1.56194826e-01  6.00173987e-01  1.20401777e-02\n",
      " -5.42110533e-01  9.95039529e-01  4.84153246e-01 -1.27042610e+00\n",
      "  3.04854369e-01  8.40147631e-01  1.45271736e+00  2.05696217e+00\n",
      "  6.76401493e-02  3.45660513e-01  9.76590813e-01  4.83403500e-01\n",
      " -4.42285497e-01 -8.26562921e-01 -2.74642952e+00  4.46444997e-01\n",
      " -7.47078289e-01  2.14256834e+00 -5.62225218e-01 -2.42924661e-02\n",
      "  4.90635603e-01  1.26483797e+00 -1.99897039e+00  1.28679541e+00\n",
      " -1.24410251e+00  1.37875369e+00 -1.78536807e+00  6.40835537e-01]\n"
     ]
    }
   ],
   "source": [
    "# NP (Noise Perturb), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "mutation_ratio = 1\n",
    "STD = 1\n",
    "(NP_train_datas, NP_train_labels), NP_model = source_mut_opts.NP_mut((train_datas, train_labels), model, mutation_ratio, STD=STD)\n",
    "\n",
    "print('Original data', train_datas[0])\n",
    "print('Mutated data after NP mutation', NP_train_datas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,994\n",
      "Trainable params: 51,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Before any mutation on model, let's see the architecture of this model. \n",
    "\n",
    "# According to the paper, there is a restriction of layer being added or removed.\n",
    "# The input and output shape of layer being added or removed are required to be same.\n",
    "\n",
    "# Hence, when you look at the architecture of this model. \n",
    "# There are layers with same input and output shape in this model for demenstration purpose.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1_copy_LR (Dense)      (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1_copy_LR (Dropout)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2_copy_LR (Dense)      (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_copy_LR (Dense)      (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5_copy_LR (Dense)      (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,722\n",
      "Trainable params: 51,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LR (Layer Removal), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(LR_train_datas, LR_train_labels), LR_model = source_mut_opts.LR_mut((train_datas, train_labels), model)\n",
    "LR_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1_copy_LAs (Dense)     (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1_copy_LAs (Dropout) (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_2_copy_LAs (Dense)     (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_copy_LAs (Dense)     (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4_copy_LAs (Dense)     (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5_copy_LAs (Dense)     (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 52,250\n",
      "Trainable params: 52,122\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LAs (Layer Addition for source-level mutation), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(LAs_train_datas, LAs_train_labels), LAs_model = source_mut_opts.LAs_mut((train_datas, train_labels), model)\n",
    "LAs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1_copy_AFRs (Dense)    (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_1_copy_AFRs (Dropout (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2_copy_AFRs (Dense)    (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3_copy_AFRs (Dense)    (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_4_copy_AFRs (Dense)    (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5_copy_AFRs (Dense)    (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 51,994\n",
      "Trainable params: 51,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# AFRs (Activation Function Removal for source-level mutation), see https://github.com/KuoTzu-yang/DeepMutation for more explanation\n",
    "(AFRs_train_datas, AFRs_train_labels), AFRs_model = source_mut_opts.AFRs_mut((train_datas, train_labels), model)\n",
    "AFRs_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
